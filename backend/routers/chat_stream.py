"""
æµå¼èŠå¤© API - SSE ç«¯ç‚¹

æä¾› Server-Sent Events æµå¼å“åº”ï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
"""
from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Dict, Optional
import json
import os

router = APIRouter(prefix="/api/ai", tags=["chat"])


class ChatMessage(BaseModel):
    role: str  # user | assistant
    content: str


class ChatRequest(BaseModel):
    session_id: str
    messages: List[ChatMessage]
    context: Optional[Dict] = None  # é¢˜ç›®ã€æ–‡ç« ç­‰ä¸Šä¸‹æ–‡ä¿¡æ¯


class ToolCallEvent(BaseModel):
    name: str
    arguments: Dict


# ä¼šè¯å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨ Redisï¼‰
_chat_sessions: Dict[str, Dict] = {}


def get_system_prompt(context: Dict = None) -> str:
    """è·å–ç³»ç»Ÿæç¤ºè¯"""
    # è¯»å– prompt æ¨¡æ¿
    prompt_path = os.path.join(os.path.dirname(__file__), "../prompts/coaching_tutor_v2.md")
    system_prompt = ""
    if os.path.exists(prompt_path):
        with open(prompt_path, "r", encoding="utf-8") as f:
            system_prompt = f.read()
    
    # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œæ›¿æ¢ prompt ä¸­çš„å ä½ç¬¦
    if context:
        # å®šä¹‰ä¸åŒé¢˜å‹çš„è§£é¢˜æŠ€å·§
        skills_map = {
            "ç»†èŠ‚ç†è§£é¢˜": """æ­¥éª¤1. é¢˜å¹²å…³é”®è¯å®šä½ï¼šæ‰¾åˆ°é¢˜ç›®ä¸­çš„å…³é”®è¯ï¼ˆå¦‚æ—¶é—´ã€åœ°ç‚¹ã€äººç‰©æˆ–äº‹ä»¶)
æ­¥éª¤2. ç¿»è¯‘é¢˜å¹²ï¼šç¿»è¯‘é¢˜å¹²æ„æ€ï¼Œå…³æ³¨ç‰¹æ®Šç–‘é—®è¯ï¼Œç†è§£éœ€è¦å›ç­”å†…å®¹ ï¼ˆåŸå› ã€å…·ä½“äº‹ç‰©ã€æ—¶é—´ã€äººç‰©ã€åœ°ç‚¹ã€æ–¹å¼ï¼‰
æ­¥éª¤3. æ–‡ç« ä¿¡æ¯å®šä½ï¼šé€šè¿‡é¢˜å¹²å…³é”®è¯è¿…é€Ÿåœ¨æ–‡ç« ä¸­æ‰¾åˆ°ç­”é¢˜æ®µè½å’Œå¥å­
æ­¥éª¤4. ä»”ç»†é˜…è¯»ç­”é¢˜æ®µè½å’Œå¥å­ï¼Œä¸é€‰é¡¹å¯¹æ¯”ï¼Œé€‰å‡ºæœ€ç¬¦åˆçš„ç­”æ¡ˆ""",
            
            "ä¸»æ—¨å¤§æ„é¢˜": """æ­¥éª¤1. é€šè¯»å…¨æ–‡ï¼šå¿«é€Ÿé€šè¯»æ–‡ç« ï¼Œè·å–æ•´ä½“æ¦‚å¿µå’Œä¸»é¢˜
æ­¥éª¤2. å¯»æ‰¾ä¸»é¢˜å¥ï¼šæ¯æ®µçš„ç¬¬ä¸€å¥æˆ–æœ€åä¸€å¥é€šå¸¸æ˜¯ä¸»é¢˜å¥ï¼Œå¸®åŠ©å½’çº³æ®µè½å¤§æ„
æ­¥éª¤3. æ¦‚æ‹¬æ€»ç»“ï¼šç»“åˆæ¯æ®µä¸»æ—¨å’Œæ–‡ç« æ¦‚å¿µï¼Œæ€»ç»“æ–‡ç« ä¸»æ—¨
æ­¥éª¤4. éªŒè¯é€‰é¡¹ï¼šå°†é€‰é¡¹å¯¹æ¯”æ€»ç»“çš„æ–‡ç« ä¸»æ—¨ï¼Œé€‰å‡ºæœ€æ¥è¿‘çš„ç­”æ¡ˆ""",
            
            "æ¨ç†åˆ¤æ–­é¢˜": """æ­¥éª¤1. å›å½’æ–‡ç« ä¿¡æ¯ï¼šæ˜ç¡®é¢˜å¹²è¦æ±‚ï¼Œæ‰¾åˆ°ç›¸å…³æ®µè½æˆ–ç›¸å…³å¥å­ä½œä¸ºç­”é¢˜ä¾æ®
æ­¥éª¤2. ç†è§£è¡¨é¢å«ä¹‰ï¼šç¿»è¯‘ç›¸å…³æ®µè½æˆ–å¥å­ï¼Œå…³æ³¨ä¸Šä¸‹æ–‡
æ­¥éª¤3. åˆ†æéšå«ä¿¡æ¯ï¼šå…³æ³¨ç›¸å…³å¥å­å’Œæ®µè½å¤„çš„éšå«ä¿¡æ¯ï¼Œç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œé€»è¾‘æ¨ç†
æ­¥éª¤4. éªŒè¯é€‰é¡¹ï¼šå°†é€‰é¡¹é€ä¸€ä¸æ‰€æ¨æ–­å†…å®¹å¯¹æ¯”ï¼Œé€‰å‡ºä¸æ¨æ–­å†…å®¹ä¸€è‡´çš„ç­”æ¡ˆ""",
            
            "è¯ä¹‰çŒœæµ‹é¢˜": """æ­¥éª¤1. ç¿»è¯‘ä¸Šä¸‹æ–‡ï¼šä»”ç»†é˜…è¯»ç›®æ ‡è¯å‰åçš„å¥å­ï¼Œè¿›è¡Œç¿»è¯‘
æ­¥éª¤2. æ³¨æ„é€»è¾‘å…³ç³»ï¼šé€šè¿‡ç¿»è¯‘åˆ†æä¸Šä¸‹æ–‡ä¸ç›®æ ‡è¯ä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼Œåˆ¤æ–­è¯ä¹‰å€¾å‘
æ­¥éª¤3. ç»“åˆè¯­å¢ƒæ¨æµ‹ï¼šç»“åˆé€»è¾‘å…³ç³»å’Œä¸Šä¸‹æ–‡ç¿»è¯‘ï¼Œæ¨æµ‹ç”Ÿè¯æ„æ€
æ­¥éª¤4. éªŒè¯é€‰é¡¹ï¼šå°†é€‰é¡¹é€ä¸€ä»£å…¥åˆ°ç›®æ ‡è¯å¤„ï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆçŒœæµ‹çš„æ„æ€ï¼Œé€‰å‡ºæ­£ç¡®é€‰é¡¹""",
            
            "ä»£è¯æŒ‡ä»£é¢˜": """æ­¥éª¤1. å®šä½ä»£è¯ï¼šè¯†åˆ«é¢˜å¹²ä¸­ç›¸å…³çš„ä»£è¯ï¼Œå¹¶å®šä½ä»£è¯åœ¨åŸæ–‡çš„ä½ç½®
æ­¥éª¤2. ç†è§£ä¸Šä¸‹æ–‡ï¼šé˜…è¯»å¹¶ç¿»è¯‘ä»£è¯å‰åçš„å¥å­æˆ–æ®µè½
æ­¥éª¤3. åˆ†æå…³ç³»ï¼šåˆ¤æ–­ä»£è¯ä¸å¥å­ä¸­çš„å…¶ä»–éƒ¨åˆ†çš„æŒ‡ä»£å…³ç³»ï¼Œæ˜ç¡®æŒ‡ä»£å†…å®¹
æ­¥éª¤4. æ›¿æ¢éªŒè¯ï¼šå°†é€‰é¡¹ä»£å…¥ä»£è¯æ‰€åœ¨å¥å­ï¼ŒéªŒè¯æ˜¯å¦ç¬¦åˆè¯­ä¹‰å’Œé€»è¾‘"""
        }

        # è·å–å½“å‰é¢˜å‹çš„è§£é¢˜æŠ€å·§ï¼Œé»˜è®¤ä¸ºç»†èŠ‚ç†è§£é¢˜
        q_type = context.get('question_type', 'ç»†èŠ‚ç†è§£é¢˜')
        current_skills = skills_map.get(q_type, skills_map["ç»†èŠ‚ç†è§£é¢˜"])

        # å‡†å¤‡æ›¿æ¢æ•°æ®
        replacements = {
            "{{article_content}}": context.get('article_content', ''),
            "{{question_stem}}": context.get('question_stem', ''),
            "{{options}}": json.dumps(context.get('options', []), ensure_ascii=False, indent=2),
            "{{correct_answer}}": context.get('correct_answer', ''),
            "{{question_type}}": q_type,
            "{{solving_skills}}": context.get('solving_skills', current_skills)
        }
        
        # æ‰§è¡Œæ›¿æ¢
        for key, value in replacements.items():
            system_prompt = system_prompt.replace(key, str(value))
            
    return system_prompt


async def generate_sse_stream(request: ChatRequest):
    """ç”Ÿæˆ SSE äº‹ä»¶æµ"""
    from services.ai_service import get_coaching_ai_generator
    from services.agents.coaching_tools import COACHING_TOOLS
    
    # è·å–æˆ–åˆ›å»ºä¼šè¯
    session = _chat_sessions.get(request.session_id, {
        "messages": [],
        "context": request.context or {},
        "wrong_count": 0
    })
    
    # æ›´æ–°ä¸Šä¸‹æ–‡
    if request.context:
        session["context"].update(request.context)
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    for msg in request.messages:
        if msg.role == "user":
            session["messages"].append({"role": "user", "content": msg.content})
    
    # æ„å»ºæ¶ˆæ¯å†å²
    messages = session["messages"]
    
    # è·å–ç³»ç»Ÿæç¤ºè¯
    system_prompt = get_system_prompt(session["context"])
    
    # è°ƒç”¨æµå¼ç”Ÿæˆ
    full_response = ""
    tool_calls = []
    
    try:
        # get_coaching_ai_generator æ ¹æ®é…ç½®é€‰æ‹© Gemini æˆ– Doubao
        for event in get_coaching_ai_generator(
            messages=messages,
            tools=COACHING_TOOLS,
            system_prompt=system_prompt
        ):
            if event["type"] == "text":
                # å‘é€æ–‡æœ¬å¢é‡
                data = json.dumps({"type": "text", "content": event["content"]}, ensure_ascii=False)
                yield f"data: {data}\n\n"
                full_response += event["content"]
                
            elif event["type"] == "tool_call":
                # å‘é€å·¥å…·è°ƒç”¨
                tool_calls.append(event["content"])
                data = json.dumps({"type": "tool_call", "content": event["content"]}, ensure_ascii=False)
                yield f"data: {data}\n\n"
                
            elif event["type"] == "done":
                # ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
                if full_response:
                    session["messages"].append({"role": "assistant", "content": full_response})
                
                # å‘é€å®Œæˆäº‹ä»¶
                data = json.dumps({
                    "type": "done",
                    "content": full_response,
                    "tool_calls": tool_calls
                }, ensure_ascii=False)
                yield f"data: {data}\n\n"
                
            elif event["type"] == "error":
                data = json.dumps({"type": "error", "content": event["content"]}, ensure_ascii=False)
                yield f"data: {data}\n\n"
        
        # æ›´æ–°ä¼šè¯
        _chat_sessions[request.session_id] = session
        
    except Exception as e:
        error_data = json.dumps({"type": "error", "content": str(e)}, ensure_ascii=False)
        yield f"data: {error_data}\n\n"


@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼å¯¹è¯æ¥å£ï¼Œè¿”å› SSE äº‹ä»¶æµ
    
    äº‹ä»¶ç±»å‹:
    - text: æ–‡æœ¬å¢é‡ {"type": "text", "content": "..."}
    - tool_call: å·¥å…·è°ƒç”¨ {"type": "tool_call", "content": {"name": "...", "arguments": {...}}}
    - done: å®Œæˆ {"type": "done", "content": "å®Œæ•´æ–‡æœ¬", "tool_calls": [...]}
    - error: é”™è¯¯ {"type": "error", "content": "é”™è¯¯ä¿¡æ¯"}
    """
    return StreamingResponse(
        generate_sse_stream(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"  # ç¦ç”¨ Nginx ç¼“å†²
        }
    )


async def generate_init_stream(request: ChatRequest):
    """ç”Ÿæˆåˆå§‹åŒ–é—®å€™è¯­çš„ SSE æµ"""
    import uuid
    from services.ai_service import get_coaching_ai_generator
    from services.agents.coaching_tools import COACHING_TOOLS
    
    session_id = request.session_id or str(uuid.uuid4())
    
    # åˆ›å»ºä¼šè¯
    context = request.context or {}
    _chat_sessions[session_id] = {
        "messages": [],
        "context": context,
        "wrong_count": 0
    }
    
    # å…ˆå‘é€ session_id
    yield f"data: {json.dumps({'type': 'session', 'session_id': session_id}, ensure_ascii=False)}\n\n"
    
    system_prompt = get_system_prompt(context)
    
    # æ£€æŸ¥æ˜¯å¦å…¨å¯¹
    if context.get("all_correct"):
        full_greeting = "å¤ªæ£’äº†ï¼ä½ å·²ç»åšå…¨å¯¹äº†ï¼ğŸ‰ æˆ‘ä»¬å¯ä»¥ç›´æ¥è¿›å…¥ä¸‹ä¸€é˜¶æ®µã€‚"
        yield f"data: {json.dumps({'type': 'text', 'content': full_greeting}, ensure_ascii=False)}\n\n"
        # å¯ä»¥é€‰æ‹©æ€§åœ°å‘é€ä¸€ä¸ªå®Œæˆä¿¡å·æˆ–å·¥å…·è°ƒç”¨
        return

    init_message = "å¼€å§‹æ•™å­¦ï¼Œè¯·æ‰§è¡Œ Phase 1 è¯Šæ–­æ­¥éª¤ã€‚"
    
    full_greeting = ""
    tool_calls = []
    
    try:
        for event in get_coaching_ai_generator(
            messages=[{"role": "user", "content": init_message}],
            tools=COACHING_TOOLS,
            system_prompt=system_prompt
        ):
            if event["type"] == "text":
                full_greeting += event["content"]
                # é€å—å‘é€æ–‡æœ¬
                data = json.dumps({"type": "text", "content": event["content"]}, ensure_ascii=False)
                yield f"data: {data}\n\n"
            elif event["type"] == "tool_call":
                tool_calls.append(event["content"])
                data = json.dumps({"type": "tool_call", "content": event["content"]}, ensure_ascii=False)
                yield f"data: {data}\n\n"
    except Exception as e:
        print(f"[ChatInit Stream] AI generation failed: {e}")
        # Fallback
        student_name = context.get("student_name", "åŒå­¦")
        question_index = context.get("question_index", 1)
        full_greeting = f"å“å‘€ {student_name}ï¼Œç¬¬ {question_index} é¢˜æ‰å‘é‡Œäº† ğŸ™ˆ"
        tool_calls = [{"name": "publish_voice_task", "arguments": {"instruction": "è¯·ç”¨è¯­éŸ³å‘Šè¯‰æˆ‘ä½ çš„æƒ³æ³•"}}]
        yield f"data: {json.dumps({'type': 'text', 'content': full_greeting}, ensure_ascii=False)}\n\n"
    
    # å¦‚æœ AI åªè¿”å› tool_call æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨ instruction ä½œä¸ºé—®å€™è¯­
    if not full_greeting.strip() and tool_calls:
        tc = tool_calls[0]
        instruction = tc.get("arguments", {}).get("instruction", "")
        if instruction:
            full_greeting = instruction
            yield f"data: {json.dumps({'type': 'text', 'content': full_greeting}, ensure_ascii=False)}\n\n"
    
    # ä¿å­˜åˆ°å†å²
    _chat_sessions[session_id]["messages"].append({
        "role": "assistant",
        "content": full_greeting
    })
    
    # å‘é€å®Œæˆäº‹ä»¶
    suggested_task = None
    if tool_calls:
        tc = tool_calls[0]
        task_type_map = {
            "publish_voice_task": "voice",
            "publish_highlight_task": "highlight", 
            "publish_select_task": "select"
        }
        suggested_task = {
            "type": task_type_map.get(tc["name"], "voice"),
            "instruction": tc.get("arguments", {}).get("instruction", "è¯·å®Œæˆä»»åŠ¡"),
            "target": tc.get("arguments", {}).get("target")
        }
    
    done_data = json.dumps({
        "type": "done",
        "greeting": full_greeting,
        "suggested_task": suggested_task,
        "tool_calls": tool_calls
    }, ensure_ascii=False)
    yield f"data: {done_data}\n\n"


@router.post("/chat/init-stream")
async def init_chat_session_stream(request: ChatRequest):
    """
    æµå¼åˆå§‹åŒ–èŠå¤©ä¼šè¯ - é€å­—è¾“å‡ºé—®å€™è¯­
    """
    return StreamingResponse(
        generate_init_stream(request),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.post("/chat/init")
async def init_chat_session(request: ChatRequest):
    """
    åˆå§‹åŒ–èŠå¤©ä¼šè¯
    
    è¿”å›ä¼šè¯ ID å’Œ AI ç”Ÿæˆçš„åˆå§‹é—®å€™è¯­
    """
    import uuid
    from services.ai_service import get_coaching_ai_generator
    from services.agents.coaching_tools import COACHING_TOOLS
    
    session_id = request.session_id or str(uuid.uuid4())
    
    # åˆ›å»ºä¼šè¯
    context = request.context or {}
    _chat_sessions[session_id] = {
        "messages": [],
        "context": context,
        "wrong_count": 0
    }
    
    # ä½¿ç”¨ AI ç”Ÿæˆåˆå§‹é—®å€™è¯­
    system_prompt = get_system_prompt(context)
    
    # æ„å»ºåˆå§‹æ¶ˆæ¯ï¼Œè®© AI ä»¥ Phase 1 è¯Šæ–­å¼€å§‹
    init_message = "å¼€å§‹æ•™å­¦ï¼Œè¯·æ‰§è¡Œ Phase 1 è¯Šæ–­æ­¥éª¤ã€‚"
    
    full_greeting = ""
    tool_calls = []
    
    try:
        for event in get_coaching_ai_generator(
            messages=[{"role": "user", "content": init_message}],
            tools=COACHING_TOOLS,
            system_prompt=system_prompt
        ):
            if event["type"] == "text":
                full_greeting += event["content"]
            elif event["type"] == "tool_call":
                tool_calls.append(event["content"])
    except Exception as e:
        print(f"[ChatInit] AI generation failed: {e}")
        # Fallback åˆ°å›ºå®šé—®å€™è¯­
        student_name = context.get("student_name", "åŒå­¦")
        question_index = context.get("question_index", 1)
        student_answer = context.get("student_answer", "?")
        full_greeting = f"å“å‘€ {student_name}ï¼Œç¬¬ {question_index} é¢˜æ‰å‘é‡Œäº† ğŸ™ˆ\n\nä½ é€‰äº† {student_answer}ï¼Œèƒ½æ‚„æ‚„å‘Šè¯‰ Jarvis ä¸ºä»€ä¹ˆé€‰å®ƒå—ï¼Ÿ"
        tool_calls = [{"name": "publish_voice_task", "arguments": {"instruction": "è¯·ç”¨è¯­éŸ³å‘Šè¯‰æˆ‘ä½ çš„æƒ³æ³•"}}]
    
    # å¦‚æœ AI åªè¿”å›äº† tool_call æ²¡æœ‰æ–‡æœ¬ï¼Œä½¿ç”¨ tool_call çš„ instruction ä½œä¸ºé—®å€™è¯­
    if not full_greeting.strip() and tool_calls:
        tc = tool_calls[0]
        instruction = tc.get("arguments", {}).get("instruction", "")
        if instruction:
            full_greeting = instruction
    
    # ä¿å­˜åˆ°å†å²
    _chat_sessions[session_id]["messages"].append({
        "role": "assistant",
        "content": full_greeting
    })
    
    # æå– suggested_task
    suggested_task = None
    if tool_calls:
        tc = tool_calls[0]
        task_type_map = {
            "publish_voice_task": "voice",
            "publish_highlight_task": "highlight", 
            "publish_select_task": "select"
        }
        suggested_task = {
            "type": task_type_map.get(tc["name"], "voice"),
            "instruction": tc.get("arguments", {}).get("instruction", "è¯·å®Œæˆä»»åŠ¡"),
            "target": tc.get("arguments", {}).get("target")  # article æˆ– question
        }
    
    return {
        "session_id": session_id,
        "greeting": full_greeting,
        "suggested_task": suggested_task,
        "tool_calls": tool_calls
    }


@router.get("/chat/history/{session_id}")
async def get_chat_history(session_id: str):
    """è·å–èŠå¤©å†å²"""
    session = _chat_sessions.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")
    
    return {
        "session_id": session_id,
        "messages": session["messages"],
        "context": session["context"]
    }


@router.delete("/chat/{session_id}")
async def delete_chat_session(session_id: str):
    """åˆ é™¤èŠå¤©ä¼šè¯"""
    if session_id in _chat_sessions:
        del _chat_sessions[session_id]
    return {"success": True}
