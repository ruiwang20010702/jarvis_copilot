"""
Vocab Service - å¢å¼ºç‰ˆæŸ¥è¯æœåŠ¡
ç”Ÿæˆè¯­å¢ƒç¿»è¯‘ã€éŸ³èŠ‚æ‹†åˆ†ã€AIåŠ©è®°ã€éŸ³æ ‡å’ŒTTSå‘éŸ³
"""
import os
import re
import json
import httpx
from typing import Optional, List, Dict, Any
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

# TTS éŸ³é¢‘å­˜å‚¨ç›®å½•
AUDIO_DIR = Path(__file__).parent.parent / "static" / "audio"
AUDIO_DIR.mkdir(parents=True, exist_ok=True)


class VocabService:
    """å¢å¼ºç‰ˆè¯æ±‡æŸ¥è¯¢æœåŠ¡"""
    
    def __init__(self):
        self.free_dict_url = "https://api.dictionaryapi.dev/api/v2/entries/en"
    
    async def generate_vocab_data(
        self, 
        word: str, 
        context_sentence: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´çš„è¯æ±‡å¡ç‰‡æ•°æ®
        
        Args:
            word: è¦æŸ¥è¯¢çš„å•è¯
            context_sentence: å­¦ç”Ÿåˆ’è¯æ—¶çš„åŸå¥ï¼ˆç”¨äºè¯­å¢ƒç¿»è¯‘ï¼‰
            
        Returns:
            å®Œæ•´çš„è¯æ±‡æ•°æ®å­—å…¸
        """
        from services.ai_service import ai_service
        
        result = {
            "word": word,
            "phonetic": None,
            "definition": None,
            "syllables": [],
            "example": self._extract_sentence_with_word(context_sentence, word) if context_sentence else "",
            "audio_url": None,
            "ai_memory_hint": None,
        }
        
        # 1. å°è¯•ä» Free Dictionary API è·å–éŸ³æ ‡
        api_phonetic = await self._get_phonetic(word)
        
        # 2. LLM ç”Ÿæˆï¼šè¯­å¢ƒç¿»è¯‘ + éŸ³èŠ‚ + AIåŠ©è®° + å¤‡é€‰éŸ³æ ‡
        llm_result = await self._generate_with_llm(word, context_sentence)
        result["definition"] = llm_result.get("definition", f"{word} çš„é‡Šä¹‰")
        result["syllables"] = llm_result.get("syllables", [word])
        result["ai_memory_hint"] = llm_result.get("mnemonic", "")
        
        # éŸ³æ ‡ä¼˜å…ˆä½¿ç”¨ APIï¼Œæ²¡æœ‰åˆ™ç”¨ LLM ç”Ÿæˆçš„
        result["phonetic"] = api_phonetic or llm_result.get("phonetic", "")
        
        # 3. ç”Ÿæˆ TTS éŸ³é¢‘
        result["audio_url"] = await self._generate_tts(word)
        
        return result
    
    async def _get_phonetic(self, word: str) -> Optional[str]:
        """ä» Free Dictionary API è·å–éŸ³æ ‡"""
        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(f"{self.free_dict_url}/{word}")
                if response.status_code == 200:
                    data = response.json()
                    if data and len(data) > 0:
                        # å°è¯•è·å–ç¬¬ä¸€ä¸ª phonetic
                        entry = data[0]
                        if entry.get("phonetic"):
                            return entry["phonetic"]
                        # æˆ–è€…ä» phonetics æ•°ç»„è·å–
                        for ph in entry.get("phonetics", []):
                            if ph.get("text"):
                                return ph["text"]
        except Exception as e:
            logger.warning(f"[VocabService] Failed to get phonetic for '{word}': {e}")
        return None
    
    async def _generate_with_llm(
        self, 
        word: str, 
        context_sentence: Optional[str]
    ) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM ç”Ÿæˆè¯­å¢ƒç¿»è¯‘ã€éŸ³èŠ‚æ‹†åˆ†å’Œ AI åŠ©è®°"""
        from services.ai_service import ai_service
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªè‹±è¯­è¯æ±‡åŠ©æ•™ã€‚è¯·åˆ†æä»¥ä¸‹å•è¯å¹¶è¿”å› JSON æ ¼å¼ã€‚

å•è¯: {word}
{"åŸå¥: " + context_sentence if context_sentence else ""}

è¯·è¿”å›ä»¥ä¸‹ JSON æ ¼å¼ï¼ˆåªè¿”å› JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰:
{{
    "phonetic": "å›½é™…éŸ³æ ‡ï¼Œå¦‚ /É™bËˆsest/",
    "definition": "ä¸­æ–‡é‡Šä¹‰ï¼ˆå¦‚æœæœ‰åŸå¥ï¼Œè¯·æ ¹æ®åŸå¥è¯­å¢ƒç¿»è¯‘ï¼Œæ ¼å¼å¦‚ï¼š'adj. ç€è¿·çš„ (æ­¤å¥ä¸­æŒ‡æ²‰è¿·äº...)'ï¼‰",
    "syllables": ["éŸ³èŠ‚1", "éŸ³èŠ‚2", ...],  // æŒ‰å‘éŸ³æ‹†åˆ†ï¼Œå¦‚ obsessed -> ["ob", "sessed"]
    "mnemonic": "ğŸ’¡ è¶£å‘³è®°å¿†æ³•ï¼Œå¦‚æ‹†åˆ†è”æƒ³ã€è°éŸ³ç­‰ï¼Œè¦æœ‰è¶£å¥½è®°ï¼ˆ50å­—ä»¥å†…ï¼‰"
}}
"""
        
        try:
            response = await ai_service.generate_text(prompt=prompt)
            
            # è§£æ JSON
            response = response.strip()
            if response.startswith("```"):
                response = re.sub(r'^```\w*\n?', '', response)
                response = re.sub(r'\n?```$', '', response)
            
            return json.loads(response)
        except Exception as e:
            logger.error(f"[VocabService] LLM generation failed for '{word}': {e}")
            # Fallback
            return {
                "definition": f"{word} çš„ä¸­æ–‡é‡Šä¹‰",
                "syllables": self._simple_syllable_split(word),
                "mnemonic": ""
            }
    
    def _simple_syllable_split(self, word: str) -> List[str]:
        """ç®€å•çš„éŸ³èŠ‚æ‹†åˆ†å¤‡é€‰æ–¹æ¡ˆ"""
        # æŒ‰å…ƒéŸ³æ‹†åˆ†çš„ç®€å•è§„åˆ™
        vowels = "aeiou"
        syllables = []
        current = ""
        
        for i, char in enumerate(word.lower()):
            current += char
            if char in vowels and i < len(word) - 1:
                # å…ƒéŸ³åæ£€æŸ¥æ˜¯å¦åº”è¯¥æ–­å¼€
                if len(current) >= 2:
                    syllables.append(current)
                    current = ""
        
        if current:
            if syllables:
                syllables[-1] += current
            else:
                syllables.append(current)
        
        return syllables if syllables else [word]
    
    def _extract_sentence_with_word(self, text: str, word: str) -> str:
        """ä»æ–‡æœ¬ä¸­æå–åŒ…å«ç›®æ ‡å•è¯çš„é‚£ä¸€å¥è¯"""
        if not text or not word:
            return ""
        
        # ç”¨æ­£åˆ™æŒ‰å¥å­æ‹†åˆ†ï¼ˆè€ƒè™‘ . ! ? ä½œä¸ºå¥å­ç»“æŸç¬¦ï¼‰
        # ä½†è¦æ³¨æ„ Mr. Dr. ç­‰ç¼©å†™ä¸åº”è¯¥æ‹†åˆ†
        sentences = re.split(r'(?<=[.!?])\s+(?=[A-Z])', text)
        
        # å¦‚æœæ²¡æœ‰åˆç†æ‹†åˆ†ï¼Œå°è¯•æ›´ç®€å•çš„æ–¹å¼
        if len(sentences) <= 1:
            sentences = re.split(r'(?<=[.!?])\s+', text)
        
        # æŸ¥æ‰¾åŒ…å«ç›®æ ‡å•è¯çš„å¥å­ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        word_lower = word.lower()
        for sentence in sentences:
            # æ£€æŸ¥å•è¯æ˜¯å¦åœ¨å¥å­ä¸­ï¼ˆä½œä¸ºç‹¬ç«‹å•è¯ï¼‰
            if re.search(rf'\b{re.escape(word_lower)}\b', sentence.lower()):
                return sentence.strip()
        
        # å¦‚æœæ²¡æ‰¾åˆ°å®Œå…¨åŒ¹é…ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…ï¼ˆè¯æ ¹ï¼‰
        word_stem = word_lower.rstrip('seding')  # ç®€å•å»é™¤å¸¸è§è¯å°¾
        if len(word_stem) >= 3:
            for sentence in sentences:
                if word_stem in sentence.lower():
                    return sentence.strip()
        
        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œè¿”å›ç¬¬ä¸€å¥
        return sentences[0].strip() if sentences else text
    
    async def _generate_tts(self, word: str) -> Optional[str]:
        """ç”Ÿæˆ TTS éŸ³é¢‘å¹¶ä¿å­˜åˆ°æ–‡ä»¶"""
        try:
            # ä½¿ç”¨ Edge TTS (å…è´¹ä¸”è´¨é‡å¥½)
            import edge_tts
            
            # æ–‡ä»¶åä½¿ç”¨å•è¯
            filename = f"{word.lower().replace(' ', '_')}.mp3"
            filepath = AUDIO_DIR / filename
            
            # å¦‚æœå·²å­˜åœ¨åˆ™ç›´æ¥è¿”å›
            if filepath.exists():
                return f"/static/audio/{filename}"
            
            # ç”ŸæˆéŸ³é¢‘
            communicate = edge_tts.Communicate(word, "en-US-AriaNeural")
            await communicate.save(str(filepath))
            
            logger.info(f"[VocabService] Generated TTS for '{word}': {filename}")
            return f"/static/audio/{filename}"
            
        except ImportError:
            logger.warning("[VocabService] edge_tts not installed, skipping TTS")
            return None
        except Exception as e:
            logger.error(f"[VocabService] TTS generation failed for '{word}': {e}")
            return None


# å•ä¾‹å®ä¾‹
vocab_service = VocabService()
